{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout, Input, Concatenate\n",
    "\n",
    "import json\n",
    "import keras\n",
    "import oov_prep as oov\n",
    "import data_cleaning as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences/Tags data length: 289401 289401\n",
      "('<BOS> they do not <EOS>', '<BOS> they do to <EOS>', '<BOS> i hope so <EOS>')\n",
      "('<start> PPSS DO * <end>', '<start> PPSS DO TO <end>', '<start> NN NN RB <end>')\n"
     ]
    }
   ],
   "source": [
    "# Movie conversation cleaned and POS tagged data\n",
    "with open('clean_tagged_data.json', 'r') as outfile:\n",
    "    data = json.load(outfile)\n",
    "    \n",
    "sent, tags = zip(*data['tags'])\n",
    "\n",
    "print('Sentences/Tags data length:', len(sent), len(tags))\n",
    "print(sent[:3])\n",
    "print(tags[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent[:20000]\n",
    "tags = tags[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of n-grams to build sequences\n",
    "n = 5\n",
    "\n",
    "# maximum length of sequence is n-1 since the last word will be the target prediction\n",
    "max_length = n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 779764\n",
      "Vocabulary Size: 12133\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and getting n-gram sequences\n",
    "\n",
    "tk_text = Tokenizer(filters=[])\n",
    "tk_text.fit_on_texts(sent)\n",
    "dec_sentences = tk_text.texts_to_sequences(sent)\n",
    "\n",
    "tk_tags = Tokenizer(filters=[])\n",
    "tk_tags.fit_on_texts(tags)\n",
    "dec_tagged = tk_tags.texts_to_sequences(tags)\n",
    "\n",
    "tagged_sent = zip(dec_sentences, dec_tagged)\n",
    "\n",
    "text_grams, tag_grams = oov.tagged_n_grams(tagged_sent, n)\n",
    "\n",
    "X, y, X_rev, y_rev = text_grams\n",
    "X_tag, y_tag, X_tag_rev, y_tag_rev = tag_grams\n",
    "\n",
    "vocab_size = len(tk_text.word_index)+1\n",
    "tags_size = len(tk_tags.word_index)+1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and getting n-gram sequences for sentences\n",
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(sent)\n",
    "enc_sentences = tk.texts_to_sequences(sent)\n",
    "\n",
    "X_enc_sent, y_enc_sent, X_rev_enc_sent, y_rev_enc_sent = oov.n_grams(enc_sentences, n)\n",
    "\n",
    "vocab_size = len(tk.word_index)+1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and getting n-gram sequences for tags\n",
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(tags)\n",
    "enc_tagged = tk.texts_to_sequences(tags)\n",
    "\n",
    "X_enc_tags, y_enc_tags, X_rev_enc_tags, y_rev_enc_tags = oov.n_grams(enc_tagged, n)\n",
    "\n",
    "tag_vocab_size = len(tk.word_index)+1\n",
    "print('Vocabulary Size: %d' % tag_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define senteces forward sequence bidirectional model\n",
    "\n",
    "model_sent = Sequential()\n",
    "model_sent.add(Embedding(vocab_size, 32, mask_zero=True, input_length=max_length))\n",
    "model_sent.add(Bidirectional(LSTM(8)))\n",
    "model_sent.add(Dropout(0.5))\n",
    "model_sent.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model_sent.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tags forward sequence bidirectional model\n",
    "\n",
    "model_tags = Sequential()\n",
    "model_tags.add(Embedding(tag_vocab_size, 32, mask_zero=True, input_length=max_length))\n",
    "model_tags.add(Bidirectional(LSTM(8)))\n",
    "model_tags.add(Dropout(0.5))\n",
    "model_tags.add(Dense(tag_vocab_size, activation='softmax'))\n",
    "print(model_tags.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reverse model for sentences\n",
    "\n",
    "rev_model_sent = Sequential()\n",
    "rev_model_sent.add(Embedding(vocab_size, 32, mask_zero=True, input_length=max_length))\n",
    "rev_model_sent.add(Bidirectional(LSTM(8)))\n",
    "rev_model_sent.add(Dropout(0.5))\n",
    "rev_model_sent.add(Dense(vocab_size, activation='softmax'))\n",
    "print(rev_model_sent.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reverse model for tags\n",
    "\n",
    "rev_model_tags = Sequential()\n",
    "rev_model_tags.add(Embedding(tag_vocab_size, 32, mask_zero=True, input_length=max_length))\n",
    "rev_model_tags.add(Bidirectional(LSTM(8)))\n",
    "rev_model_tags.add(Dropout(0.5))\n",
    "rev_model_tags.add(Dense(tag_vocab_size, activation='softmax'))\n",
    "print(rev_model_tags.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile sentence forward sequence network\n",
    "# loss is set to sparse_cat_cross because of multiple classes and no one-hot encoding\n",
    "\n",
    "model_sent.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['acc'])\n",
    "\n",
    "model_sent.fit(X_enc_sent, y_enc_sent, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model_sent.save('model_oov_sent.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile reverse sequence network\n",
    "\n",
    "rev_model_sent.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "rev_model_sent.fit(X_rev_enc_sent, y_rev_enc_sent, batch_size=128, epochs=5, verbose=1, shuffle=True,\n",
    "                   validation_split=0.2)\n",
    "\n",
    "rev_model_sent.save('rev_model_oov_sent.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile tags forward sequence network\n",
    "\n",
    "model_tags.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['acc'])\n",
    "\n",
    "model_tags.fit(X_enc_tags, y_enc_tags, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model_tags.save('model_oov_tags.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile reverse sequence network\n",
    "\n",
    "rev_model_tags.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "rev_model_tags.fit(X_rev_enc_tags, y_rev_enc_tags, batch_size=128, epochs=5, verbose=1, shuffle=True,\n",
    "                   validation_split=0.2)\n",
    "\n",
    "rev_model_tags.save('rev_model_oov_tags.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<bos>', 'they', 'do', 'not', '<eos>'],\n",
       " ['<bos>', 'they', 'do', 'to', '<eos>']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splt_sent = [s.lower().split() for s in sent]\n",
    "splt_sent[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = Word2Vec(splt_sent, sg=1, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tk_text.word_index.items():\n",
    "    embedding_matrix[i] = embedded.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_sentag = []\n",
    "for i in range(len(splt_sent)):\n",
    "    sentence = []\n",
    "    for ii in range(len(splt_sent[i])):\n",
    "        sentence.append(''.join([splt_sent[i][ii].lower(), splt_tags[i][ii].lower()]))\n",
    "    concat_sentag.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(concat_sentag)\n",
    "enc_sentences = tk.texts_to_sequences(concat_sentag)\n",
    "\n",
    "X_enc_sent, y_enc_sent, X_rev_enc_sent, y_rev_enc_sent = oov.n_grams(enc_sentences, n)\n",
    "\n",
    "vocab_size = len(tk.word_index)+1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sentag = []\n",
    "\n",
    "c=0\n",
    "for sent in concat_sentag:\n",
    "    embedded_sent = []\n",
    "    for word in sent:\n",
    "        embedded_sent.append(list(embedded.wv[word]))\n",
    "    emb_sentag.append(embedded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim = X.shape[0]\n",
    "in_dim = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input((3,), dtype='float32')\n",
    "model_emb = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length,\n",
    "                      trainable=False)(model_input)\n",
    "model_emb = Bidirectional(LSTM(8))(model_input)\n",
    "#model_emb = LSTM(8, input_shape=(100,32))(model_emb)\n",
    "#model_emb = Dropout(0.5)(model_emb)\n",
    "model_emb = Dense(vocab_size+1, activation='softmax')(model_emb)\n",
    "model_emb = Model(inputs = model_input, outputs = model_emb)\n",
    "model_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model_emb.fit(X, y, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model_emb.save('model_emb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_sent = Sequential()\n",
    "model_sent.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length,\n",
    "                      trainable=False))\n",
    "model_sent.add(Bidirectional(LSTM(8)))\n",
    "model_sent.add(Dropout(0.5))\n",
    "model_sent.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model_sent.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sent.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model_sent.fit(X_enc_sent, y_enc_sent, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model_sent.save('model_emb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "text = np.random.randint(5000, size=(442702, 200), dtype='int32')\n",
    "topic = np.random.randint(2, size=(442702, 227), dtype='int32')\n",
    "sentiment1 = to_categorical(np.random.randint(5, size=442702), dtype='int32')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D, Concatenate, Lambda\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import cast\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = Input(shape=(max_length,), dtype='int32', name='text')\n",
    "text_encoded = Embedding(vocab_size, output_dim=100, weights=[embedding_matrix], trainable=False)(text_input)\n",
    "text_encoded = Dropout(0.1)(text_encoded)\n",
    "text_encoded = Conv1D(300, 3, padding='valid', activation='relu', strides=1)(text_encoded)\n",
    "text_encoded = GlobalMaxPool1D()(text_encoded)\n",
    "\n",
    "tags_input = Input(shape=(max_length,), dtype='int32', name='topic')\n",
    "\n",
    "tags_float = Lambda(lambda x:cast(x, 'float32'), name='Floatconverter')(topic_input)\n",
    "\n",
    "concatenated = Concatenate(axis=-1)([text_encoded, topic_float])\n",
    "sentiment = Dense(5, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[text_input, topic_input], outputs=sentiment)\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer concatenate_8 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.sequential.Sequential'>. Full input: [<keras.engine.sequential.Sequential object at 0x000002109E10D608>, <keras.engine.sequential.Sequential object at 0x000002109E4E8A88>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 697\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.engine.sequential.Sequential'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-4373f10e9016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_tags\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    314\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer concatenate_8 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.sequential.Sequential'>. Full input: [<keras.engine.sequential.Sequential object at 0x000002109E10D608>, <keras.engine.sequential.Sequential object at 0x000002109E4E8A88>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "model_text.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length,\n",
    "                      trainable=False))\n",
    "model_text.add(Bidirectional(LSTM(8)))\n",
    "model_text.add(Dropout(0.5))\n",
    "model_text.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model_tags = Sequential()\n",
    "model_tags.add(Embedding(tags_size, 32, input_length=max_length))\n",
    "model_tags.add(Bidirectional(LSTM(8)))\n",
    "model_tags.add(Dropout(0.5))\n",
    "model_tags.add(Dense(tags_size, activation='softmax'))\n",
    "\n",
    "model = Concatenate()([model_text, model_tags])\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 4, 100)       1213300     input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 4, 100)       1213300     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_30 (Bidirectional (None, 16)           6976        embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_31 (Bidirectional (None, 16)           6976        embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32)           0           bidirectional_30[0][0]           \n",
      "                                                                 bidirectional_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 12134)        400422      concatenate_15[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,840,974\n",
      "Trainable params: 1,627,674\n",
      "Non-trainable params: 1,213,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input = Input((max_length,))\n",
    "model_text = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(text_input)\n",
    "model_text = Bidirectional(LSTM(8, dropout=0.3, recurrent_dropout=0.2))(model_text)\n",
    "#model_text = Dense(vocab_size+1, activation='softmax')(model_text)\n",
    "#model_text = Model(inputs=text_input, outputs=model_text)\n",
    "\n",
    "tags_input = Input((max_length,))\n",
    "model_tags = Embedding(vocab_size, 100)(tags_input)\n",
    "model_tags = Bidirectional(LSTM(8, dropout=0.3, recurrent_dropout=0.2))(model_tags)\n",
    "#model_tags = Dense(tags_size+1, activation='softmax')(model_tags)\n",
    "#model_tags = Model(inputs=tags_input, outputs=model_tags)\n",
    "\n",
    "concatenate = Concatenate()([model_text, model_tags])\n",
    "result = Dense(vocab_size+1, activation='softmax')(concatenate)\n",
    "\n",
    "model = Model(inputs=[text_input, tags_input], outputs=result)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623811 samples, validate on 155953 samples\n",
      "Epoch 1/5\n",
      "623811/623811 [==============================] - 865s 1ms/step - loss: 5.7519 - accuracy: 0.1301 - val_loss: 5.4767 - val_accuracy: 0.1696\n",
      "Epoch 2/5\n",
      "623811/623811 [==============================] - 873s 1ms/step - loss: 5.1936 - accuracy: 0.1690 - val_loss: 5.4260 - val_accuracy: 0.1773\n",
      "Epoch 3/5\n",
      "623811/623811 [==============================] - 935s 1ms/step - loss: 5.0268 - accuracy: 0.1740 - val_loss: 5.4468 - val_accuracy: 0.1820\n",
      "Epoch 4/5\n",
      "623811/623811 [==============================] - 981s 2ms/step - loss: 4.9310 - accuracy: 0.1768 - val_loss: 5.4653 - val_accuracy: 0.1846\n",
      "Epoch 5/5\n",
      "623811/623811 [==============================] - 990s 2ms/step - loss: 4.8638 - accuracy: 0.1784 - val_loss: 5.4801 - val_accuracy: 0.1837\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model.fit([X, X_tag], y, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model.save('model_concat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 4, 100)       1213300     input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 4, 100)       1213300     input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 4, 100)       1213300     input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 4, 100)       1213300     input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_40 (Bidirectional (None, 16)           6976        embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_41 (Bidirectional (None, 16)           6976        embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_42 (Bidirectional (None, 16)           6976        embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_43 (Bidirectional (None, 16)           6976        embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 32)           0           bidirectional_40[0][0]           \n",
      "                                                                 bidirectional_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 32)           0           bidirectional_42[0][0]           \n",
      "                                                                 bidirectional_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 64)           0           concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 12134)        788710      concatenate_24[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,669,814\n",
      "Trainable params: 3,243,214\n",
      "Non-trainable params: 2,426,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input = Input((max_length,))\n",
    "model_text = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(text_input)\n",
    "model_text = Bidirectional(LSTM(8, dropout=0.2, recurrent_dropout=0.1))(model_text)\n",
    "\n",
    "tags_input = Input((max_length,))\n",
    "model_tags = Embedding(vocab_size, 100)(tags_input)\n",
    "model_tags = Bidirectional(LSTM(8, dropout=0.2, recurrent_dropout=0.1))(model_tags)\n",
    "\n",
    "concatenate_text_tags = Concatenate()([model_text, model_tags])\n",
    "\n",
    "rev_text_input = Input((max_length,))\n",
    "rev_model_text = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(rev_text_input)\n",
    "rev_model_text = Bidirectional(LSTM(8, dropout=0.2, recurrent_dropout=0.1))(rev_model_text)\n",
    "\n",
    "rev_tags_input = Input((max_length,))\n",
    "rev_model_tags = Embedding(vocab_size, 100)(rev_tags_input)\n",
    "rev_model_tags = Bidirectional(LSTM(8, dropout=0.2, recurrent_dropout=0.1))(rev_model_tags)\n",
    "\n",
    "rev_concatenate_text_tags = Concatenate()([rev_model_text, rev_model_tags])\n",
    "\n",
    "concatenate = Concatenate()([concatenate_text_tags, rev_concatenate_text_tags])\n",
    "\n",
    "result = Dense(vocab_size+1, activation='softmax')(concatenate)\n",
    "\n",
    "model = Model(inputs=[text_input, tags_input, rev_text_input, rev_tags_input], outputs=result)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623811 samples, validate on 155953 samples\n",
      "Epoch 1/5\n",
      "623811/623811 [==============================] - 1437s 2ms/step - loss: 3.1135 - accuracy: 0.5407 - val_loss: 2.0454 - val_accuracy: 0.7239\n",
      "Epoch 2/5\n",
      "623811/623811 [==============================] - 1448s 2ms/step - loss: 1.6537 - accuracy: 0.7232 - val_loss: 1.8021 - val_accuracy: 0.7797\n",
      "Epoch 3/5\n",
      "623811/623811 [==============================] - 1328s 2ms/step - loss: 1.2919 - accuracy: 0.7643 - val_loss: 1.7162 - val_accuracy: 0.8047\n",
      "Epoch 4/5\n",
      "623811/623811 [==============================] - 1315s 2ms/step - loss: 1.0879 - accuracy: 0.7899 - val_loss: 1.6862 - val_accuracy: 0.8182\n",
      "Epoch 5/5\n",
      "623811/623811 [==============================] - 1346s 2ms/step - loss: 0.9515 - accuracy: 0.8082 - val_loss: 1.6454 - val_accuracy: 0.8275\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model.fit([X, X_tag, X_rev, X_tag_rev], y, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model.save('model_full_concat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
