{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout, Input, Concatenate\n",
    "\n",
    "import json\n",
    "import keras\n",
    "import oov_prep as oov\n",
    "import data_cleaning as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences/Tags data length: 289401 289401\n",
      "('<BOS> they do not <EOS>', '<BOS> they do to <EOS>', '<BOS> i hope so <EOS>')\n",
      "('<start> PPSS DO * <end>', '<start> PPSS DO TO <end>', '<start> NN NN RB <end>')\n"
     ]
    }
   ],
   "source": [
    "# Movie conversation cleaned and POS tagged data\n",
    "with open('clean_tagged_data.json', 'r') as outfile:\n",
    "    data = json.load(outfile)\n",
    "    \n",
    "sent, tags = zip(*data['tags'])\n",
    "\n",
    "print('Sentences/Tags data length:', len(sent), len(tags))\n",
    "print(sent[:3])\n",
    "print(tags[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent[:20000]\n",
    "tags = tags[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of n-grams to build sequences\n",
    "n = 5\n",
    "\n",
    "# maximum length of sequence is n-1 since the last word will be the target (y)\n",
    "max_length = n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 779764\n",
      "Vocabulary Size: 12133\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and getting n-gram sequences\n",
    "\n",
    "tk_text = Tokenizer(filters=[])\n",
    "tk_text.fit_on_texts(sent)\n",
    "dec_sentences = tk_text.texts_to_sequences(sent)\n",
    "\n",
    "tk_tags = Tokenizer(filters=[])\n",
    "tk_tags.fit_on_texts(tags)\n",
    "dec_tagged = tk_tags.texts_to_sequences(tags)\n",
    "\n",
    "tagged_sent = zip(dec_sentences, dec_tagged)\n",
    "\n",
    "text_grams, tag_grams = oov.tagged_n_grams(tagged_sent, n)\n",
    "\n",
    "X, y, X_rev, y_rev = text_grams\n",
    "X_tag, y_tag, X_tag_rev, y_tag_rev = tag_grams\n",
    "\n",
    "vocab_size = len(tk_text.word_index)+1\n",
    "tags_size = len(tk_tags.word_index)+1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<bos>', 'they', 'do', 'not', '<eos>'],\n",
       " ['<bos>', 'they', 'do', 'to', '<eos>']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting sentences for word2vec\n",
    "splt_sent = [s.lower().split() for s in sent]\n",
    "splt_sent[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding words with word2vec (skip-gram)\n",
    "embedded = Word2Vec(splt_sent, sg=1, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embedding_matrix to associate embedding with encoded sequences\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tk_text.word_index.items():\n",
    "    embedding_matrix[i] = embedded.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Training for OOV Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 4, 100)       1213300     input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 4, 100)       1213300     input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 4, 100)       1213300     input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 4, 100)       1213300     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_44 (Bidirectional (None, 32)           14976       embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_45 (Bidirectional (None, 32)           14976       embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_46 (Bidirectional (None, 32)           14976       embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_47 (Bidirectional (None, 32)           14976       embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 64)           0           bidirectional_44[0][0]           \n",
      "                                                                 bidirectional_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 64)           0           bidirectional_46[0][0]           \n",
      "                                                                 bidirectional_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 128)          0           concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 12134)        1565286     concatenate_27[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 6,478,390\n",
      "Trainable params: 4,051,790\n",
      "Non-trainable params: 2,426,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# using n-grams of sentences, tags, reversed sentences and reversed tags\n",
    "# using word2vec embedding for sentences and standard keras embedding for tags\n",
    "# concatenating each model to get a more reliable prediction \n",
    "\n",
    "text_input = Input((max_length,))\n",
    "model_text = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(text_input)\n",
    "model_text = Bidirectional(LSTM(16, dropout=0.2, recurrent_dropout=0.1))(model_text)\n",
    "\n",
    "tags_input = Input((max_length,))\n",
    "model_tags = Embedding(vocab_size, 100)(tags_input)\n",
    "model_tags = Bidirectional(LSTM(16, dropout=0.2, recurrent_dropout=0.1))(model_tags)\n",
    "\n",
    "concatenate_text_tags = Concatenate()([model_text, model_tags])\n",
    "\n",
    "rev_text_input = Input((max_length,))\n",
    "rev_model_text = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(rev_text_input)\n",
    "rev_model_text = Bidirectional(LSTM(16, dropout=0.2, recurrent_dropout=0.1))(rev_model_text)\n",
    "\n",
    "rev_tags_input = Input((max_length,))\n",
    "rev_model_tags = Embedding(vocab_size, 100)(rev_tags_input)\n",
    "rev_model_tags = Bidirectional(LSTM(16, dropout=0.2, recurrent_dropout=0.1))(rev_model_tags)\n",
    "\n",
    "rev_concatenate_text_tags = Concatenate()([rev_model_text, rev_model_tags])\n",
    "\n",
    "concatenate = Concatenate()([concatenate_text_tags, rev_concatenate_text_tags])\n",
    "\n",
    "result = Dense(vocab_size+1, activation='softmax')(concatenate)\n",
    "\n",
    "model = Model(inputs=[text_input, tags_input, rev_text_input, rev_tags_input], outputs=result)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623811 samples, validate on 155953 samples\n",
      "Epoch 1/5\n",
      "623811/623811 [==============================] - 1437s 2ms/step - loss: 3.1135 - accuracy: 0.5407 - val_loss: 2.0454 - val_accuracy: 0.7239\n",
      "Epoch 2/5\n",
      "623811/623811 [==============================] - 1448s 2ms/step - loss: 1.6537 - accuracy: 0.7232 - val_loss: 1.8021 - val_accuracy: 0.7797\n",
      "Epoch 3/5\n",
      "623811/623811 [==============================] - 1328s 2ms/step - loss: 1.2919 - accuracy: 0.7643 - val_loss: 1.7162 - val_accuracy: 0.8047\n",
      "Epoch 4/5\n",
      "623811/623811 [==============================] - 1315s 2ms/step - loss: 1.0879 - accuracy: 0.7899 - val_loss: 1.6862 - val_accuracy: 0.8182\n",
      "Epoch 5/5\n",
      "623811/623811 [==============================] - 1346s 2ms/step - loss: 0.9515 - accuracy: 0.8082 - val_loss: 1.6454 - val_accuracy: 0.8275\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model.fit([X, X_tag, X_rev, X_tag_rev], y, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "model.save('model_full_concat.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
